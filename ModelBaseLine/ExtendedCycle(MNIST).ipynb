{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae3edf4-c268-4edf-a848-2474000c5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "plt.style.use('seaborn-v0_8-dark-palette')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc737785-59bc-4254-bb5d-c5981f415dad",
   "metadata": {},
   "source": [
    "#### Updates:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e66866-e9bb-485b-8b62-35ddc3d40f2d",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <b>In this cycle we add:</b>\n",
    "    <li>Save and load model functions</li>\n",
    "    <li>Added lr_scheduler using</li>\n",
    "    <li>Added early stopping</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1666df-e2bf-456a-ad1b-4626da36f0e3",
   "metadata": {},
   "source": [
    "#### Define device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5c3bec-1c4f-4d1a-9ba9-6f84b469ffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344d234-15a9-4865-8047-8474855c3608",
   "metadata": {},
   "source": [
    "#### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91455af6-23b1-493e-b113-941675578200",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.len_dataset = 0\n",
    "        self.data_list = []\n",
    "\n",
    "        for path_dir, dir_list, file_list in os.walk(path):\n",
    "            if path_dir == path:\n",
    "                self.classes = sorted(dir_list)\n",
    "                self.class_to_index = {\n",
    "                    cls_name: i for i, cls_name in enumerate(self.classes)\n",
    "                }\n",
    "                continue\n",
    "\n",
    "            cls = path_dir.split('/')[-1]\n",
    "\n",
    "            for name_file in file_list:\n",
    "                file_path = os.path.join(path_dir, name_file)\n",
    "                self.data_list.append((file_path, self.class_to_index[cls]))\n",
    "\n",
    "            self.len_dataset += len(file_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path, target = self.data_list[index]\n",
    "        sample = np.array(Image.open(file_path))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6121ea-38ca-4426-915b-476007e55a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "transform = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=(0.5,), std=(0.5,))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6552384f-e8d4-4ef4-a6ba-45ddedabc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "# note: you need to run scripts from dataloader part\n",
    "path = os.path.join(os.getcwd(), 'mnist')\n",
    "train_data = MNISTDataset(os.path.join(path, 'training'), transform=transform)\n",
    "test_data = MNISTDataset(os.path.join(path, 'testing'), transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33fa4a9-3a83-485e-aa55-53a737da7ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class = 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x72a70c0835b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some info\n",
    "img, target = train_data[8]\n",
    "\n",
    "print(f'class = {target}')\n",
    "plt.imshow(img.numpy()[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83ab0d2-82be-4b08-9f7d-47dc68f7975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data, val_data = random_split(train_data, [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced39c23-dced-406c-92e4-c3ad20646b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data on batches\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69adbf62-0773-48e6-898b-92d57d4b9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data, val_data, test_data = random_split(dataset, [0.7, 0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12720b3-07f6-4f7c-959d-8a6fbeb8053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data on batches\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb87376-4255-4543-8235-432e9bc1a196",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0233f532-dc47-45a1-9ffc-7bacf820c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(input, 128)\n",
    "        self.layer_2 = nn.Linear(128, output)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.act(x)\n",
    "        out = self.layer_2(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df947d1a-b09e-44d8-aca1-13d416c47f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(784, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e8147a-f1f3-468d-b4c2-90378f73a4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "input = torch.rand([16, 784], dtype=torch.float32).to(device)\n",
    "\n",
    "out = model(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c23561-230b-4bbd-b285-52733ea8c2d8",
   "metadata": {},
   "source": [
    "#### Setup loss, optimizer and lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56effcda-db5a-4c52-93d7-6b34739de7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup loss GD optimizer\n",
    "loss_model = nn.MSELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# lr_scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    opt,\n",
    "    mode='min',\n",
    "    factor=1e-1,\n",
    "    threshold=1e-4,\n",
    "    # patience=5,\n",
    "    threshold_mode='rel',\n",
    "    cooldown=0,\n",
    "    min_lr=0,\n",
    "    eps=1e-08\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c38a7-2722-43b3-8189-2b6a8e7eb7d2",
   "metadata": {},
   "source": [
    "#### Define Early Stopping class(note: we could do it easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27beed13-c731-41fa-a8ba-1849958cd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, mode='min', patience=10, threshold=1e-5, threshold_mode='rel'):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('Param mode can be only mах and min.')\n",
    "        if threshold_mode not in {'rel', 'abs'}:\n",
    "            raise ValueError('Param threshold_mode can be only rel and abs.')\n",
    "        if threshold > 1.0:\n",
    "            raise ValueError('Param threshold must be less than 1.0.')\n",
    "        if not isinstance(threshold, float):\n",
    "            raise TypeError('Param threshold must be float и and less than 1,0.')\n",
    "        if not isinstance(patience, int):\n",
    "            raise TypeError('Param patience must be int.')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.threshold = threshold\n",
    "        self.threshold_mode = threshold_mode\n",
    "        self.count = 0\n",
    "        self.best = None\n",
    "\n",
    "    def __call__(self, tracked_parameter):\n",
    "        current = float(tracked_parameter)\n",
    "        if self.best is None:\n",
    "            self.best = current\n",
    "            return False\n",
    "\n",
    "        if self.changed_better(current, self.best):\n",
    "            self.best = current\n",
    "            self.count = 0\n",
    "        else:\n",
    "            self.count += 1\n",
    "\n",
    "        if self.count >= self.patience:\n",
    "            self.count = 0\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def changed_better(self, current, best):\n",
    "        if self.mode == 'min' and self.threshold_mode == 'rel':\n",
    "            return current < best - best * self.threshold\n",
    "\n",
    "        elif self.mode == 'min' and self.threshold == 'abs':\n",
    "            return current < best - self.threshold\n",
    "\n",
    "        elif self.mode == 'max' and self.threshold_mode == 'rel':\n",
    "            return current > best + best * self.threshold\n",
    "\n",
    "        else: # mode == 'max' and threshold == 'abs'\n",
    "            return current > best + self.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37efce0e-7a0c-4f68-a29f-195a45b394ec",
   "metadata": {},
   "source": [
    "#### Setup checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "760ab461-e9e4-4d43-8d55-6d04bb34518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "lr_list = []\n",
    "best_loss = None\n",
    "str_info = \"\"\"\n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self, input, output):\n",
    "            super().__init__()\n",
    "            self.layer_1 = nn.Linear(input, 128)\n",
    "            self.layer_2 = nn.Linear(128, output)\n",
    "            self.act = nn.ReLU()\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = self.layer_1(x)\n",
    "            x = self.act(x)\n",
    "            out = self.layer_2(x)\n",
    "            return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeff924-fb92-40c5-ac67-aeb817e6291f",
   "metadata": {},
   "source": [
    "#### Extend our traning cycle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c944e2c-cdb9-4025-8aaa-19a5bd3ae6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train_loss = 1.6177, train_acc = 0.6176, val_loss = 0.1275, val_acc = 0.6893, lr=0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# add progress bar\u001b[39;00m\n\u001b[1;32m     13\u001b[0m train_loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, targets \u001b[38;5;129;01min\u001b[39;00m train_loop:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# (batch_size, 1, 64, 64) -> (batch_size, 64 * 64)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1180\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1177\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1180\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m, in \u001b[0;36mDatasetReg.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m coords \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict_coords[name_file], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 27\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, coords\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m needs_unpacking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/v2/_transform.py:55\u001b[0m, in \u001b[0;36mTransform.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     46\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params(\n\u001b[1;32m     47\u001b[0m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m flat_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[1;32m     53\u001b[0m ]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_unflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:862\u001b[0m, in \u001b[0;36mtree_unflatten\u001b[0;34m(leaves, treespec)\u001b[0m\n\u001b[1;32m    858\u001b[0m     spec \u001b[38;5;241m=\u001b[39m _tree_flatten_helper(tree, leaves, is_leaf\u001b[38;5;241m=\u001b[39mis_leaf)\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leaves, spec\n\u001b[0;32m--> 862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(leaves: Iterable[Any], treespec: TreeSpec) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyTree:\n\u001b[1;32m    863\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Given a list of values and a TreeSpec, builds a pytree.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m    This is the inverse operation of `tree_flatten`.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(treespec, TreeSpec):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# training cycle\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # train model\n",
    "    model.train() # setup train mode\n",
    "    # we will save our loss\n",
    "    running_train_loss = []\n",
    "    # add metric(accuracy)\n",
    "    true_answer = 0\n",
    "    # add progress bar\n",
    "    train_loop = tqdm(train_loader, leave=False)\n",
    "    for x, targets in train_loop:\n",
    "        # data\n",
    "        # (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
    "        x = x.reshape(-1, 28 * 28).to(device)\n",
    "        # (batch_size, int) -> (batch_size, 10, dtype=float32)\n",
    "        targets = targets.reshape(-1).to(torch.int32)\n",
    "        targets = torch.eye(10)[targets].to(device)\n",
    "        \n",
    "        # forward pass + loss calc\n",
    "        pred = model(x)\n",
    "        loss = loss_model(pred, targets)\n",
    "\n",
    "        # backward pass\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # optimization step\n",
    "        opt.step()\n",
    "\n",
    "        running_train_loss.append(loss.item())\n",
    "        mean_train_loss = sum(running_train_loss) / len(running_train_loss)\n",
    "\n",
    "        true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        # add description to progress bar\n",
    "        train_loop.set_description(f'Epoch [{epoch + 1}/{EPOCHS}], train_loss = {mean_train_loss:.4f}')\n",
    "\n",
    "    # calc metric\n",
    "    running_train_accuracy = true_answer / len(train_data)\n",
    "    \n",
    "    # save loss and metric\n",
    "    train_loss.append(mean_train_loss)\n",
    "    train_acc.append(running_train_accuracy)\n",
    "    \n",
    "    # check model(validation)\n",
    "    model.eval() # setup model into validation mode\n",
    "    with torch.no_grad(): # disable grad calculation\n",
    "        # do the same for loss on validation\n",
    "        running_val_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in val_loader:\n",
    "            # data\n",
    "            # (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
    "            x = x.reshape(-1, 28 * 28).to(device)\n",
    "            # (batch_size, int) -> (batch_size, 10, dtype=float32)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(10)[targets].to(device)\n",
    "\n",
    "            # forward pass + loss calculation\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_val_loss.append(loss.item())\n",
    "            mean_val_loss = sum(running_val_loss) / len(running_val_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        # calc metric\n",
    "        running_val_acc = true_answer / len(val_data)\n",
    "            \n",
    "        # save loss and metric\n",
    "        val_loss.append(mean_val_loss)\n",
    "        val_acc.append(running_val_acc)\n",
    "\n",
    "    lr_scheduler.step(mean_val_loss)\n",
    "    lr = lr_scheduler._last_lr[0]\n",
    "    lr_list.append(lr)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{EPOCHS}], train_loss = {mean_train_loss:.4f}, train_acc = {running_train_accuracy:.4f}, val_loss = {mean_val_loss:.4f}, val_acc = {running_val_acc:.4f}, lr={lr:.4f}')\n",
    "\n",
    "    if best_loss is None:\n",
    "        best_loss = mean_val_loss\n",
    "\n",
    "    # simpliest case\n",
    "    # usualy do something like this: best_loss - mean_val_loss < threshold\n",
    "    if mean_val_loss < best_loss:\n",
    "        checkpoints = {\n",
    "                    'info': str_info,\n",
    "                    'state_model': model.state_dict(),\n",
    "                    'state_opt': opt.state_dict(),\n",
    "                    'state_lr_scheduler': lr_scheduler.state_dict(),\n",
    "                    'loss': {\n",
    "                        'train_loss': train_loss,\n",
    "                        'val_loss': val_loss,\n",
    "                        'best_loss': best_loss\n",
    "                    },\n",
    "                    'metric': {\n",
    "                        'train_acc': train_acc,\n",
    "                        'val_acc': val_acc\n",
    "                    },\n",
    "                    'lr': lr_list,\n",
    "                    'epoch': {\n",
    "                        'EPOCHS': EPOCHS,\n",
    "                        'save_epoch': epoch\n",
    "                    }\n",
    "                    }\n",
    "\n",
    "        torch.save(model.state_dict(), f'model_state_dict_epoch_{epoch + 1}.pt')\n",
    "        print(f'On epoch - {epoch + 1}, model has been saved with loss function on validation - {mean_val_loss:.4f}', end='\\n\\n')\n",
    "        # check early stopping\n",
    "        if early_stopping(mean_val_loss):\n",
    "            print(f'\\033[31mTraining stopped on {epoch + 1} epoch. \\033[0m')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b2b1d-9f20-484e-b800-e6cd52a41f79",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1b9c1-b014-41e3-b8ea-f16d29992817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lr_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548450bc-0593-4477-bfd8-6091e2a0eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss_train', 'loss_val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd089b1c-de46-4952-9c0b-2f78a8aa50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend(['acc_train', 'acc_val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379951c4-7dda-470e-bc8a-78a2fb1b8cbf",
   "metadata": {},
   "source": [
    "##### Load and test our model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1baea6-2212-4732-9b92-088382fcace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = torch.load('model_state_dict_epoch_3.pt')\n",
    "# ВНИМАНИЕ!!! Тут у тебя просто немного другой словарь!\n",
    "model.load_state_dict(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09b378-3521-402c-ab3d-89ec2654f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        running_test_loss = []\n",
    "        true_answer = 0\n",
    "        for x, targets in test_loader:\n",
    "            # data\n",
    "            # (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
    "            x = x.reshape(-1, 28 * 28).to(device)\n",
    "            # (batch_size, int) -> (batch_size, 10, dtype=float32)\n",
    "            targets = targets.reshape(-1).to(torch.int32)\n",
    "            targets = torch.eye(10)[targets].to(device)\n",
    "\n",
    "            # forward pass + loss calculation\n",
    "            pred = model(x)\n",
    "            loss = loss_model(pred, targets)\n",
    "\n",
    "            running_test_loss.append(loss.item())\n",
    "            mean_test_loss = sum(running_test_loss) / len(running_test_loss)\n",
    "\n",
    "            true_answer += (pred.argmax(dim=1) == targets.argmax(dim=1)).sum().item()\n",
    "            \n",
    "        # calc metric\n",
    "        running_test_acc = true_answer / len(test_data)\n",
    "            \n",
    "print(f'test_loss = {mean_test_loss:.4f}, test_acc = {running_test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
