{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5e6a2-e910-4c43-9b82-51f60625aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d304fe-47dd-40c2-b27d-bfb0fd6e5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from array import array\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bf7b9-cd6e-4785-ab7a-9a0f32623743",
   "metadata": {},
   "source": [
    "### MNIST dataset local creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bb127-272d-4b25-a049-f39f93b67aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = path.join(os.getcwd(), 'sample_data')\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21474e-9f91-4e83-a79d-e9711860038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=data_path, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61febef3-c077-4d2a-ac52-a4fd9e78d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(dataset, data_path):\n",
    "    \n",
    "    if dataset == 'training':\n",
    "        path_img = path.join(data_path, 'MNIST/raw/train-images-idx3-ubyte')\n",
    "        path_lbl = path.join(data_path, 'MNIST/raw/train-labels-idx1-ubyte')\n",
    "    elif dataset == 'testing':\n",
    "        path_img = path.join(data_path, 'MNIST/raw/t10k-images-idx3-ubyte')\n",
    "        path_lbl = path.join(data_path, 'MNIST/raw/t10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must be 'training' or 'testing'!\")\n",
    "\n",
    "    with open(path_lbl, 'rb') as f_label:\n",
    "        _, size = struct.unpack('>II', f_label.read(8))\n",
    "        lbl = array('b', f_label.read())\n",
    "\n",
    "    with open(path_img, 'rb') as f_img:\n",
    "        _, size, rows, cols = struct.unpack('>IIII', f_img.read(16))\n",
    "        img = array(\"B\", f_img.read())\n",
    "\n",
    "    return lbl, img, size, rows, cols\n",
    "\n",
    "\n",
    "def write_dataset(labels, data, size, rows, cols, output_dir):\n",
    "    classes = {i: f'class_{i}' for i in range(10)}\n",
    "\n",
    "    output_dirs = [\n",
    "        path.join(output_dir, classes[i])\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    for dir in output_dirs:\n",
    "        if not path.exists(dir):\n",
    "            os.makedirs(path.join(os.getcwd(), dir), exist_ok=True)\n",
    "\n",
    "    # write data\n",
    "    for (i, label) in enumerate(labels):\n",
    "        output_filename = path.join(output_dirs[label], str(i) + '.jpg')\n",
    "        print('Writing ' + output_filename)\n",
    "\n",
    "        with open(output_filename, 'wb') as h:\n",
    "            data_i = [\n",
    "                data[ (i*rows*cols + j*cols) : (i*rows*cols + (j+1)*cols) ]\n",
    "                for j in range(rows)\n",
    "            ]\n",
    "            data_array = np.asarray(data_i)\n",
    "\n",
    "            im = Image.fromarray(data_array)\n",
    "            im.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91fed45-2ff3-4ec3-9580-a6d6ad41ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'mnist'\n",
    "\n",
    "for dataset in ['training', 'testing']:\n",
    "    write_dataset(*read(dataset, data_path), path.join(output_path, dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e0df18-4f4f-44c7-b18b-dac616be6180",
   "metadata": {},
   "source": [
    "### Regression dataset local creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ecb2a-a1cf-432e-af2f-aaafd82569aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('dataset'):\n",
    "    os.mkdir(path.join(os.getcwd(), 'dataset'))\n",
    "\n",
    "img = np.random.randint(0, 50, [100000, 64, 64], dtype=np.uint8)\n",
    "square = np.random.randint(100, 200, [100000, 15, 15], dtype=np.uint8)\n",
    "\n",
    "coords = np.empty([100000, 2])\n",
    "\n",
    "data = {}\n",
    "\n",
    "for i in range(img.shape[0]):\n",
    "\n",
    "    x = np.random.randint(20, 44)\n",
    "    y = np.random.randint(20, 44)\n",
    "\n",
    "    img[i, (y - 7):(y + 8), (x - 7):(x + 8)] = square[i]\n",
    "\n",
    "    coords[i] = [y, x]\n",
    "\n",
    "    name_img = f'img_{i}.jpeg'\n",
    "    path_img = path.join('dataset/', name_img)\n",
    "\n",
    "    image = Image.fromarray(img[i])\n",
    "    image.save(path_img)\n",
    "\n",
    "    data[name_img] = [y, x]\n",
    "\n",
    "with open('dataset/coords.json', 'w') as f:\n",
    "    json.dump(data, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
